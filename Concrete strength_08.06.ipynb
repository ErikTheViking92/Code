{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709c45b8",
   "metadata": {},
   "source": [
    "# **Predicting Concrete Compressive Strength**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64197c3",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d801f",
   "metadata": {},
   "source": [
    "Concrete is a fundamental material in civil engineering. Its compressive strength is crucial for ensuring the safety and durability of structures. However, accurately determining this strength is challenging because it depends on a non-linear relationship between several factors, including the concrete's age and the proportions of its components, such as cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate and fine aggregate.\n",
    "\n",
    "The aim of this project is to apply machine learning techniques to improve the prediction of concrete strength in order to contribute to better design, quality control and optimization of resources in construction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4686791",
   "metadata": {},
   "source": [
    "## 2. Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02e184",
   "metadata": {},
   "source": [
    "To enable a meaningful analysis, this chapter begins with a brief description of the dataset, including its origin, structure, and variable definitions. In preparation for modeling, several preprocessing steps are performed. These include importing the raw data, correcting data types, handling missing values, and defining input and the target variable. This ensures that the data is clean, consistent, and ready for subsequent machine learning analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81193386",
   "metadata": {},
   "source": [
    "### 2.1. Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7ed51",
   "metadata": {},
   "source": [
    "The dataset originates from the UCI Machine Learning Repository and comprises 1,030 observations, 8 quantitative input variables and 1 quantitative output variable.\n",
    "\n",
    "The input variables are `cement`, `blast furnace slag`, `fly ash`, `water`, `superplasticizer`, `coarse aggregate`, `fine aggregate` and `age`. Except for `age`, the other variables represent ingredient quantities in the concrete mixture, measured in *kg in a $m^{3}$* mixture. `Age` is measured in *days*. `Concrete compressive strength`, the target variable, is measured in *MPa*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9627cd",
   "metadata": {},
   "source": [
    "### 2.2. Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92e5a7",
   "metadata": {},
   "source": [
    "The first step of the analysis involves importing the required libraries and loading the dataset.\n",
    "\n",
    "In this case, the dataset is read from `Concrete_data.csv`. This file contains the composition of different concrete mixtures along with their corresponding compressive strength values. To ensure consistent formatting, parameters such as the field separator, decimal notation, and encoding are explicitly specified during data import. Additionally, column names are stripped of leading and trailing whitespaces for cleaner access.\n",
    "\n",
    "The table below displays the first few rows of the dataset. Each row represents a unique concrete mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880071ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn\n",
    "import graphviz\n",
    "import os\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from itertools import combinations\n",
    "from IPython.display import display, Math, Image\n",
    "\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score, mean_absolute_error,root_mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.inspection import PartialDependenceDisplay,partial_dependence\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot') \n",
    "sns.set_style(\"darkgrid\")\n",
    "# print numpy arrays with precision 4\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f38ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_df = pd.read_csv('./Concrete_data.csv', \n",
    "                          sep = ',',\n",
    "                         decimal = ',',\n",
    "                         encoding = 'UTF-8')\n",
    "concrete_df.columns = concrete_df.columns.str.strip()\n",
    "concrete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fd740",
   "metadata": {},
   "source": [
    "### 2.3. Data type correction and missing value handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eedbe5",
   "metadata": {},
   "source": [
    "To ensure numerical consistency across all variables, features initially read as object types — due to locale-specific formatting or encoding — are explicitly converted to numeric data types using `pd.to_numeric`. Invalid entries that cannot be parsed are coerced into NaN values. Subsequently, a missing value check is conducted, and all rows containing NaN entries are removed from the dataset to maintain data integrity and compatibility with machine learning algorithms.\n",
    "\n",
    "The table below shows the original and converted data types of all variables. Object-type features were converted to numeric formats (e.g., float64) to enable their use in regression analysis. Finally, the number of rows containing missing values (NaN) is also reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a66d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original data types：\")\n",
    "print(concrete_df.dtypes)\n",
    "\n",
    "# object to numeric\n",
    "for col in concrete_df.columns:\n",
    "    if concrete_df[col].dtype == 'object':\n",
    "        concrete_df[col] = pd.to_numeric(concrete_df[col], errors='coerce')\n",
    "\n",
    "\n",
    "print(\"\\nTransfromed datatypes：\")\n",
    "print(concrete_df.dtypes)\n",
    "\n",
    "# NaN \n",
    "print(\"\\nRows with NaN：\", concrete_df.isna().sum().sum())\n",
    "\n",
    "# Drop NaN\n",
    "concrete_df = concrete_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef25fe",
   "metadata": {},
   "source": [
    "### 2.4. Definition of input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfa303",
   "metadata": {},
   "source": [
    "In the following, we construct the input matrix `X` and the output vector `y` for a linear regression model. This is done by selecting `concrete compressive strength` as the target variable and treating all remaining columns as input features.\n",
    "\n",
    "To improve the clarity of visualizations and tables, the feature names are shortened by omitting component numbers and units. The original component order is preserved and displayed in a separate column for reference. Finally, the selected feature names are printed to confirm the correct setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(col):\n",
    "    # Remove parentheses and their contents (component numbers and units) from column names\n",
    "    col = re.sub(r'\\(.*?\\)', '', col)\n",
    "    col = re.sub(r'component\\s*\\d*', '', col, flags=re.IGNORECASE)\n",
    "    return col.strip().replace('  ', ' ')\n",
    "\n",
    "concrete_df.columns = [clean_column_name(col) for col in concrete_df.columns]\n",
    "concrete_df.head()\n",
    "\n",
    "# Relabel the response variable\n",
    "label_column = 'Concrete compressive strength'\n",
    "# Redefine feature columns after cleaning\n",
    "feature_columns = [c for c in concrete_df.columns if c != label_column]\n",
    "#define all the variables we need for the linear regression with concrete compressive strength as response and all other variables as possible features\n",
    "X = concrete_df[feature_columns].values\n",
    "y = concrete_df[label_column].values\n",
    "p = len(feature_columns)\n",
    "print(\"Features are:\", feature_columns,\n",
    "      \"\\nThe response variable is:\", label_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1decde",
   "metadata": {},
   "source": [
    "### 2.5. Explanation of relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64d331",
   "metadata": {},
   "source": [
    "In order to facilitate a more profound comprehension of the function of each input variable, the table below summarizes the meaning and expected influence of each feature on concrete strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e5eae",
   "metadata": {},
   "source": [
    "| Variable             | Meaning                              | Expected Effect on Strength    |\n",
    "| -------------------- | ------------------------------------ | ------------------------------ |\n",
    "| `cement`             | Binder                               | increases strength          |\n",
    "| `blast_furnace_slag` | Supplementary binder                 | increases strength or neutral                  |\n",
    "| `fly_ash`            | Supplementary binder                 | increase strength or neutral                  |\n",
    "| `water`              | Affects workability and hydration    | decreases strength (excess) |\n",
    "| `superplasticizer`   | Increases workability, reduces water | increase or decrease depending on context  |\n",
    "| `coarse_aggregate`   | Filler                               | neutral or mild effect         |\n",
    "| `fine_aggregate`     | Filler                               | neutral or mild effect         |\n",
    "| `age`                | Curing time                          | increases strength          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a91e9a",
   "metadata": {},
   "source": [
    "### 2.6. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d63ace",
   "metadata": {},
   "source": [
    "To ensure comparability between features and to improve the performance of algorithms sensitive to scale, the input variables are standardized using Z-score normalization, resulting in features with zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d63ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4222a",
   "metadata": {},
   "source": [
    "### 2.7. Distribution of target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ce3c9",
   "metadata": {},
   "source": [
    "To better understand the statistical properties of the response variable (`compressive strength`), we visualize its distribution using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ce3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(concrete_df[label_column], kde=True)\n",
    "plt.title(\"Distribution of Compressive Strength\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45cea8",
   "metadata": {},
   "source": [
    "The histogram plot clearly indicates that the compressive strength data is neither uniformly nor normally distributed. Instead, it exhibits a sporadic and spread-out pattern, with many unique or infrequent strength values and some concentration toward the distribution’s tails.\n",
    "\n",
    "This lack of strong central tendency suggests that assumption-heavy models, such as simple linear regression, may not perform optimally. Therefore, it is advisable to consider more robust models such as decision trees. While linear regression can still be applied as a baseline, the observed distribution helps explain its potential limitations in predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f350c73",
   "metadata": {},
   "source": [
    "### 2.8. Correlation between relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0979030",
   "metadata": {},
   "source": [
    "To explore the linear relationships among the variables, a correlation matrix is computed and visualized using a heatmap. This analysis highlights both the correlations between input features and the target variable, as well as potential multicollinearity among the input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0979030",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = concrete_df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efae5f9",
   "metadata": {},
   "source": [
    "#### 2.8.1. Variables that influence concrete strength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c0c0b",
   "metadata": {},
   "source": [
    "According to the heatmap results, `cement` has a moderately strong positive correlation with concrete strength, with a value of +0.50. This indicates that more cement usually leads to stronger concrete. `Superplasticiser` also has a positive effect, with a value of +0.37.\n",
    "`Age` also has a positive effect, as concrete strengthens over time.\n",
    "`Water` has a negative correlation with strength of -0.29, meaning more water tends to weaken concrete. This observation is consistent with **Abrams' water-to-cement ratio pronouncement**, which emphasises that an increased water-to-cement ratio typically reduces concrete strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a432c",
   "metadata": {},
   "source": [
    "#### 2.8.2. Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1de13",
   "metadata": {},
   "source": [
    "The highest level of multicollinearity is found in the correlation between `water` and `superplasticiser`, which has a value of -0.66. This indicates that they carry overlapping yet opposing information. There is also a moderate correlation between `cement`, `blast furnace slag` and `fly ash` because these materials may act as partial substitutes in the concrete mix and therefore tend to move in opposite directions.\n",
    "\n",
    "To gain a more precise understanding of potential collinearity among the input variables, we compute the **Variance Inflation Factor (VIF)** for each predictor. **VIF** quantifies how much the variance of a regression coefficient is inflated due to the linear dependence of that variable on the others. It serves as a diagnostic tool to detect multicollinearity, which can adversely affect the interpretability and stability of regression models. As mentioned in the Machine Learning and Data Analytics (MLDA) lecture content, a **VIF** of 1 shows an absence of collinearity, whereas collinearity usually occurs when the **VIF** is greater than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIFs = [(predictor, variance_inflation_factor(X,_)) \\\n",
    "        for _,predictor in enumerate(list(feature_columns))] \n",
    "print('Variance Inflation Factors')\n",
    "for tup in VIFs:\n",
    "    print('{:20}'.format(tup[0]), '{:.3f}'.format(tup[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548c1f1",
   "metadata": {},
   "source": [
    "As shown in the table above, the variance inflation factors (VIFs) are notably high for `coarse aggregate`, `water`,`fine aggregate`,`cement`, `superplasticizer`, `fly ash` and `blast furnace slag`. This indicates a substantial degree of multicollinearity among these input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc3bb0",
   "metadata": {},
   "source": [
    "## 3. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64af85",
   "metadata": {},
   "source": [
    "This project aims to predict concrete compressive strength which is a problem with a quantitative response. According to the lecture content in the fundamental part of MLDA, this task is a **regression task**. In the following part, linear regression, ridge regression, lasso regression, one decision-tree based method are applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93fa95",
   "metadata": {},
   "source": [
    "### 3.1. Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b4e14",
   "metadata": {},
   "source": [
    "#### 3.1.1 Validation set approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e2e93c",
   "metadata": {},
   "source": [
    "In supervised machine learning, the objective is to develop a model that performs well not only on the training data but also on previously unseen data. To evaluate this generalization ability, the dataset is split into a **training set** (80%) and a **test set** (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed459d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecbccf",
   "metadata": {},
   "source": [
    "#### 3.1.2. K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe6acf",
   "metadata": {},
   "source": [
    "To evaluate the model more reliably, the **K-fold method** is used. In this approach, the data is split into K parts; each part is used once as the validation set while the remaining parts form the training set. The results from all K iterations are then averaged to reduce the bias from a single split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f395c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the kfold, shuffle the training and test dataset every time\n",
    "kf = KFold(n_splits=10, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a359c5",
   "metadata": {},
   "source": [
    "##### 3.1.3. Scorers for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5bad04",
   "metadata": {},
   "source": [
    "To evaluate the performance of the model during cross-validation, two standardized scoring metrics are employed: the **Mean Squared Error (MSE)** and the **coefficient of determination**, denoted as **R²**.\n",
    "\n",
    "The **MSE** quantifies the average of the squared differences between the predicted and the actual values, with lower values indicating a more accurate model fit. \n",
    "\n",
    "In contrast, the **R² score** assesses the proportion of variance in the dependent variable that is predictable from the independent variables, where values approaching 1 imply stronger explanatory and predictive capabilities. \n",
    "\n",
    "To ensure consistency in their application within the evaluation framework, both metrics are encapsulated using the `make_scorer()` function, thereby facilitating their integration into subsequent model assessment procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f730f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MSE scorer \n",
    "mse_scorer = make_scorer(mean_squared_error)\n",
    "\n",
    "# Create r2 scorer \n",
    "r2 = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98567950",
   "metadata": {},
   "source": [
    "### 3.2. Explanation of the dataset with statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44baf2bb",
   "metadata": {},
   "source": [
    "#### 3.2.1. Statsmodel, outliers and high leverege points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a1046",
   "metadata": {},
   "source": [
    "To gain statistical insights into the impact of individual input features on concrete compressive strength, an **Ordinary Least Squares (OLS)** regression model is fitted using the statsmodels library. \n",
    "\n",
    "First, the feature matrix `X_stat` is constructed by selecting all input variables from the dataset and appending a constant term to account for the intercept. The target variable `y_stat` corresponds to the concrete compressive strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statsmodel fitting, it is used to show the p-values\n",
    "X_stat = sm.add_constant(concrete_df.iloc[:,0:-1])\n",
    "y_stat = concrete_df[label_column]\n",
    "\n",
    "statmodel = sm.OLS(y_stat,X_stat)\n",
    "estimate = statmodel.fit()\n",
    "\n",
    "print(estimate.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d06a91",
   "metadata": {},
   "source": [
    "Based on the result of the fitted model, a statistically significant relationship is observed between `concrete compressive strength` and several input variables, namely `cement`, `blast furnace slag`, `fly ash`, `water`, `superplasticizer`, and `age`, as indicated by their respective **p-values** being below the conventional threshold of **0.05**.\n",
    "\n",
    "The fitted OLS model yields an **R-squared value** of approximately 0.62, indicating that around 62% of the variance in concrete compressive strength can be explained by the selected predictors. This suggests a moderate level of explanatory power. The **adjusted R-squared**, which accounts for the number of predictors in the model, supports this conclusion. The **F-statistic** is relatively high, and the **corresponding p-value** is close to zero, confirming that the model as a whole is statistically significant and that the predictors are jointly informative.\n",
    "\n",
    "However, some diagnostic indicators point to potential issues. The **Omnibus test** suggests minor deviations from normality in the residuals, while the **Durbin–Watson statistic** is below 2, indicating the presence of positive autocorrelation. Although these issues are not severe, they may affect the model's reliability. \n",
    "\n",
    "Consequently, in the next step, regularized regression techniques such as Ridge or Lasso will be explored to mitigate multicollinearity and enhance predictive performance. Prior to that, all features will be standardized, and the models will be implemented using **scikit-learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbefaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the residuals, studentized residuals and the leverages\n",
    "fitted_values = estimate.fittedvalues\n",
    "residuals = estimate.resid.values\n",
    "studentized_residuals = OLSInfluence(estimate).resid_studentized_internal\n",
    "leverages = OLSInfluence(estimate).influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f352674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate thresholds\n",
    "n = len(fitted_values)\n",
    "p = X.shape[1] - 1  # exclude constant\n",
    "leverage_thresh = (p + 1) / n\n",
    "\n",
    "# Convert to arrays\n",
    "studentized_residuals = np.asarray(studentized_residuals)\n",
    "leverages = np.asarray(leverages)\n",
    "\n",
    "# Identify outlier indices\n",
    "outlier_indices = np.where(np.abs(studentized_residuals) > 3)[0]\n",
    "high_leverage_indices = np.where(leverages > leverage_thresh)[0]\n",
    "outliers = []\n",
    "for idx in outlier_indices:\n",
    "    outliers.append(idx)\n",
    "print(\"Outliers are:\",outliers)\n",
    "\n",
    "# Find common indices (both outlier and high leverage)\n",
    "joint_outliers = np.intersect1d(outlier_indices, high_leverage_indices)\n",
    "high_leverage_and_outliers = [] \n",
    "\n",
    "for idx in joint_outliers:\n",
    "    high_leverage_and_outliers.append(idx)\n",
    "print(\"Comments on joint outliers (in both ax2 and ax3):\",high_leverage_and_outliers)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# 1. Residuals plot\n",
    "ax1.scatter(fitted_values, residuals, facecolors='none', edgecolors='b')\n",
    "ax1.set_xlabel('Fitted values')\n",
    "ax1.set_ylabel('Residuals')\n",
    "\n",
    "# 2. Studentized Residuals plot\n",
    "ax2.scatter(fitted_values, studentized_residuals, facecolors='none', edgecolors='b')\n",
    "ax2.axhline(y=3, color='r', linestyle='--', linewidth=1)\n",
    "ax2.axhline(y=-3, color='r', linestyle='--', linewidth=1)\n",
    "# Mark joint outliers\n",
    "for idx in joint_outliers:\n",
    "    ax2.scatter(fitted_values[idx], studentized_residuals[idx], color='red')\n",
    "    ax2.annotate(idx, (fitted_values[idx], studentized_residuals[idx]), color='red', fontsize=8)\n",
    "ax2.set_xlabel('Fitted values')\n",
    "ax2.set_ylabel('Studentized residuals')\n",
    "\n",
    "# 3. Leverage vs Studentized Residuals\n",
    "ax3.scatter(leverages, studentized_residuals, facecolors='none', edgecolors='b')\n",
    "ax3.axhline(y=3, color='r', linestyle='--', linewidth=1)\n",
    "ax3.axhline(y=-3, color='r', linestyle='--', linewidth=1)\n",
    "ax3.axvline(x=leverage_thresh, color='g', linestyle='--', linewidth=1)\n",
    "# Mark joint outliers\n",
    "for idx in joint_outliers:\n",
    "    ax3.scatter(leverages[idx], studentized_residuals[idx], color='red')\n",
    "    ax3.annotate(idx, (leverages[idx], studentized_residuals[idx]), color='red', fontsize=8)\n",
    "ax3.set_xlabel('Leverage')\n",
    "ax3.set_ylabel('Studentized residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fef1e",
   "metadata": {},
   "source": [
    "The residuals display a clear pattern, which suggests **non-linearity** in the data. The studentized residuals indicate the presence of two outliers. The leverage plot also reveals several high-leverage points—defined as points with leverage greater than $(p+1)/n=9/1030\\approx 0.009$. Notably, both outliers are also high-leverage points. However, since the dataset does not clearly define criteria for excluding data points, all observations, including the outliers, are retained for the subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58257947",
   "metadata": {},
   "source": [
    "### 3.3. Prediction with scikit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b6fd9",
   "metadata": {},
   "source": [
    "##### Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data by scaling features\n",
    "scaler = StandardScaler()\n",
    "model = make_pipeline(scaler, LinearRegression())\n",
    "\n",
    "mse_scores_lin = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "r2_scores = cross_val_score(model, X_train, y_train, scoring='r2', cv=kf)\n",
    "\n",
    "print(\"\\nAverage MSE across folds:\", -np.mean(mse_scores_lin))\n",
    "print(\"\\nAverage R2 across folds:\", np.mean(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539a97b",
   "metadata": {},
   "source": [
    "Validation set approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb86122",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = model.fit(X_train, y_train)\n",
    "y_pred = linear.predict(X_test)\n",
    "# print the mse\n",
    "print(\"Test MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d9916",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "1. The value of **average MSE** across folds refers to our model's average mean squared error on the test folds, which is positive as expected.\n",
    "2. **Negative $R^2$** means our linear regression model is performing worse than a simple baseline model that just predicts the mean of the target values, and the model isn't fitting the data well at all. ##not that sure\n",
    "\n",
    "To improve the regression, following we will try first polynomial features, and then regularized regression (Ridge and Lasso)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e7ddb",
   "metadata": {},
   "source": [
    "#### Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a75252",
   "metadata": {},
   "source": [
    "In this section, polynomial regression is used because there is non-linearity between the features and the target variable. To prevent overfitting due to using excessively high polynomial degrees, we evaluate models with varying degrees and select the one with the lowest mean squared error (MSE). This optimal degree is then used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try polynomial features with degree 2 to 4\n",
    "# Store MSE scores for each degree\n",
    "degree_mse = {}\n",
    "\n",
    "# Loop through polynomial degrees from 2 to 4\n",
    "for degree in range(2, 5):\n",
    "    model_poly = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    mse_scores = cross_val_score(model_poly, X_train, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    avg_mse = -np.mean(mse_scores)\n",
    "\n",
    "    degree_mse[degree] = avg_mse\n",
    "    print(f\"Degree {degree}: Average MSE = {avg_mse:.4f}\")\n",
    "    \n",
    "\n",
    "# Find the degree with the lowest MSE\n",
    "best_degree = min(degree_mse, key=degree_mse.get)\n",
    "print(f\"\\nBest polynomial degree: {best_degree} (MSE = {degree_mse[best_degree]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = best_degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Fit the model with the best polynomial degree\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test_poly_scaled)\n",
    "\n",
    "# Calculate MSE and R2 for the test set\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test MSE: {test_mse:.2f}\")\n",
    "print(f\"Test R2: {test_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55cdad",
   "metadata": {},
   "source": [
    "The training MSE and the test MSE are very close with training mse equal to 50.48 and test mse as 51.12. This indicates that the model generalizes well to unseen data and is not just memorizing the training set. Hence, there is no significant overfitting. If the model were overfitting, we would expect the training MSE to be much lower than the test MSE.\n",
    "So for follwing analyzing the degree equal to 3 will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9388c3b",
   "metadata": {},
   "source": [
    "#### Forward stepwise selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7100cf",
   "metadata": {},
   "source": [
    "Perform a forward stepwise selection to determine the best set of features. As the criterion for the comparison of the different models, estimate the metrics using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_selection_mse_r2(X, y, max_features=None):\n",
    "    n_features = X.shape[1]\n",
    "    selected = []\n",
    "    remaining = list(range(n_features))\n",
    "    best_mse_list = []\n",
    "    best_r2_list = []\n",
    "    \n",
    "    if max_features is None:\n",
    "        max_features = n_features\n",
    "\n",
    "    while len(selected) < max_features:\n",
    "        candidates = []\n",
    "        for candidate in remaining:\n",
    "            features = selected + [candidate]\n",
    "            model = LinearRegression()\n",
    "            mse = -np.mean(cross_val_score(model, X[:, features], y, scoring='neg_mean_squared_error', cv=kf))\n",
    "            r2 = np.mean(cross_val_score(model, X[:, features], y, scoring='r2', cv=kf))\n",
    "            candidates.append((mse, r2, candidate))\n",
    "\n",
    "        # choose the minimum of mse\n",
    "        candidates.sort()\n",
    "        best_mse, best_r2, best_candidate = candidates[0]\n",
    "\n",
    "        selected.append(best_candidate)\n",
    "        remaining.remove(best_candidate)\n",
    "        best_mse_list.append(best_mse)\n",
    "        best_r2_list.append(best_r2)\n",
    "\n",
    "    return selected, best_mse_list, best_r2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial features with degree 3\n",
    "poly = PolynomialFeatures(degree=best_degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "forward_feature_names = poly.get_feature_names_out(input_features  = feature_columns)\n",
    "\n",
    "selected_features, mse_list, r2_list= forward_stepwise_selection_mse_r2(X_train_poly, y_train)\n",
    "#print(selected_features, mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_selection = []\n",
    "best_index = np.argmin(mse_list)\n",
    "for i, (mse, r2, feature_idx) in enumerate(zip(mse_list, r2_list, selected_features), 1):\n",
    "    current_selection.append(feature_idx)\n",
    "    forward_selected_names = [forward_feature_names[j] for j in current_selection]\n",
    "    if i == best_index + 1:\n",
    "        print(f\"Best MSE: {mse:.4f} | Best R²: {r2:.4f} | Features: {forward_selected_names}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train_poly[:, current_selection], y_train)\n",
    "y_pred = model.predict(X_test_poly[:, current_selection])\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\" Test MSE: {test_mse:.4f} | Test R²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f92b7a",
   "metadata": {},
   "source": [
    "#### Ridge regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'neg_mean_squared_error': 'neg_mean_squared_error', 'r2': 'r2'}\n",
    "\n",
    "# define the model\n",
    "ridgemodel = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(degree = best_degree),\n",
    "    GridSearchCV(\n",
    "        estimator = Ridge(),\n",
    "        cv = kf,\n",
    "        scoring = scoring,\n",
    "        refit = 'neg_mean_squared_error', # redit the model based on the mse\n",
    "        \n",
    "        # param_grid determines the parameters to test (alpha is lambda in the Ridge estimator)\n",
    "        # np.logspace(-3, 2, 50): array from 10^-3 to 10^2 in 50 steps (base default is 10, can also be something else)\n",
    "        param_grid = {'alpha': np.logspace(-3, 2, 50)},\n",
    "    )\n",
    ")\n",
    "ridgemodel.fit(X_train, y_train)\n",
    "#print(ridgemodel[2].cv_results_) #to show the results and names\n",
    "\n",
    "# obtain the results\n",
    "lambdas = [p['alpha'] for p in ridgemodel[2].cv_results_['params']]\n",
    "mses = [neg_mse * -1 for neg_mse in ridgemodel[2].cv_results_['mean_test_neg_mean_squared_error']]\n",
    "r2 = [r2 for r2 in ridgemodel[2].cv_results_['mean_test_r2']]\n",
    "    \n",
    "best_model = ridgemodel.named_steps['gridsearchcv'].best_estimator_\n",
    "best_mse = min(mses)\n",
    "best_r2 = max(r2)\n",
    "\n",
    "best_lambda_mse = lambdas[np.argmin(mses)]\n",
    "best_lambda_r2 = lambdas[np.argmax(r2)]\n",
    "\n",
    "print(f\"Best alpha regarding mse: {best_lambda_mse:.2f}, with MSE: {best_mse:.2f}\")\n",
    "print(f\"Best alpha regarding r2: {best_lambda_r2:.2f}, with r2: {best_r2:.2f}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612774b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reults\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "ax.plot(lambdas, mses)\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(r\"MSE as a function of $\\lambda$\")\n",
    "ax.set_xlabel(r\"Hyper-parameter $\\lambda$\")\n",
    "ax.set_ylabel(\"Estimated MSE\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e50621",
   "metadata": {},
   "source": [
    "The ridge regression was evaluated across a range of λ values from $10^{-3}$ to $10^2$. The validation MSE decreased with small increases in λ due to reduced overfitting, reaching a minimum at λ = 0.45. Beyond this point, further increases in λ caused the model to underfit the data, resulting in higher MSEs.\n",
    "Thus, the optimal λ value was selected as 0.45, where the model achieved the lowest MSE of 59.34. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-3, 6, 50)\n",
    "coefficients = list()\n",
    "\n",
    "# for each lambda define and fit the model and save the obtained parameters in the coefficients list\n",
    "for lam in lambdas:\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(degree = best_degree),\n",
    "        Ridge(alpha = lam)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    coefficients.append(model[2].coef_)\n",
    "    \n",
    "    \n",
    "# plot the results    \n",
    "coefficients = np.array(coefficients).T\n",
    "fig, ax = plt.subplots(figsize = (12, 10))\n",
    "\n",
    "for coef_vals in coefficients:\n",
    "    ax.plot(lambdas, coef_vals)\n",
    "\n",
    "ax.set_xlabel(r\"Hyper-parameter $\\lambda$\")\n",
    "ax.set_ylabel(r\"Value of the model coefficients $\\beta_i$\")\n",
    "ax.set_xscale('log');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b423095",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = ridgemodel.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse:.2f}\")\n",
    "print(f\"Test R2: {test_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed60a52",
   "metadata": {},
   "source": [
    "#### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with GridSearchCV\n",
    "lassomodel = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(degree = best_degree, interaction_only=False, include_bias=False),\n",
    "    GridSearchCV(\n",
    "        estimator = Lasso(max_iter = 10000, tol = 1e-4),\n",
    "        param_grid={'alpha': np.logspace(-3, 1.5, 50)},\n",
    "        scoring=scoring,\n",
    "        refit='neg_mean_squared_error',\n",
    "        cv=kf\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit the pipeline\n",
    "lassomodel.fit(X_train, y_train)\n",
    "#print(lassomodel[2].cv_results_)\n",
    "\n",
    "# Extract CV results\n",
    "grid = lassomodel.named_steps['gridsearchcv']\n",
    "lassolambdas = [p['alpha'] for p in grid.cv_results_['params']]\n",
    "mses_lasso = [-score for score in grid.cv_results_['mean_test_neg_mean_squared_error']]  # convert from negative MSE\n",
    "r2_lasso = grid.cv_results_['mean_test_r2']\n",
    "\n",
    "# Get best values\n",
    "best_lassomodel = grid.best_estimator_\n",
    "best_lassomse = min(mses_lasso)\n",
    "best_lassor2 = max(r2_lasso)\n",
    "\n",
    "best_lambda_mse_lasso = lassolambdas[np.argmin(mses_lasso)]\n",
    "best_lambda_r2_lasso = lassolambdas[np.argmax(r2_lasso)]\n",
    "\n",
    "print(f\"Best alpha regarding mse: {best_lambda_mse_lasso:.3f}, with MSE: {best_lassomse:.2f}\")\n",
    "print(f\"Best alpha regarding r2: {best_lambda_r2_lasso:.3f}, with R2: {best_lassor2:.3f}\")\n",
    "\n",
    "# plot the results\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "ax.plot(lambdas, mses_lasso)\n",
    "ax.set_xscale('log')\n",
    "ax.set_title(r\"MSE as a function of $\\lambda$\")\n",
    "ax.set_xlabel(r\"Hyper-parameter $\\lambda$\")\n",
    "ax.set_ylabel(\"Estimated MSE\");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a120408",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lassomodel.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse:.2f}\")\n",
    "print(f\"Test R2: {test_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cd5f8",
   "metadata": {},
   "source": [
    "It can be noticed that the test MSE and $R^2$ are similar to the ones obtained with the Ridge regression, because the alpha = 0,010 is very small, so the Lasso regression is almost equivalent to the Ridge regression.\n",
    "So the next step is try to find the coefficients of the Lasso regression, to see if some of them are zero and if some of them are close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405b04e",
   "metadata": {},
   "source": [
    "Non-zero coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = [f\"x{i}\" for i in range(X.shape[1])\n",
    "\n",
    "# Extract from the fitted polynomial step\n",
    "poly = lassomodel.named_steps['polynomialfeatures']\n",
    "feature_names = poly.get_feature_names_out(input_features = feature_columns)\n",
    "\n",
    "# Get final fitted Lasso model\n",
    "lasso = lassomodel.named_steps['gridsearchcv'].best_estimator_\n",
    "\n",
    "# Get coefficients\n",
    "coefs = lasso.coef_\n",
    "\n",
    "# Combine with feature names\n",
    "lasso_selected_features = [name for name, coef in zip(feature_names, coefs) if coef != 0]\n",
    "zero_features = [(name, coef) for name, coef in zip(feature_names, coefs) if coef == 0]\n",
    "\n",
    "print(\"Non-zero coefficients:\", np.sum(lasso.coef_ != 0))\n",
    "print(\"Total features:\", len(lasso.coef_))\n",
    "print(\"Zero coefficients:\", zero_features)\n",
    "\n",
    "lasso_weights = pd.Series(coefs, index=feature_names)\n",
    "lasso_weights.sort_values(key=abs, ascending=False)  # sort by absolute value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6be30",
   "metadata": {},
   "source": [
    "Only one coefficient x0 x2 is set to zero, but there are many features that are close to zero, which means that they are probably not important for the model. So we try to set a threshold to filter the features and try to find the best features for the model, regarding different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4337a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial features transformation\n",
    "poly = PolynomialFeatures(degree = best_degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "feature_names = poly.get_feature_names_out(feature_columns)\n",
    "\n",
    "# Scale the features and apply polynomial transformation\n",
    "scaler = StandardScaler()\n",
    "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Define the Lasso model with GridSearchCV\n",
    "best_lasso = grid.best_estimator_\n",
    "coefs = pd.Series(best_lasso.coef_, index=feature_names)\n",
    "\n",
    "# Thresholds for feature selection\n",
    "thresholds = np.linspace(0, 2.5, 50)  # 50 thresholds from 0 to 2.5\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    selected = coefs[np.abs(coefs) >= threshold]\n",
    "    selected_indices = [i for i, name in enumerate(feature_names) if name in selected.index]\n",
    "    lasso_threshold_selected_names = list(selected.index)  # get names from coef Series\n",
    "\n",
    "    if len(selected_indices) == 0:\n",
    "        continue  # skip if no features are selected\n",
    "\n",
    "    X_train_selected = X_train_poly_scaled[:, selected_indices]\n",
    "    X_test_selected = X_test_poly_scaled[:, selected_indices]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "\n",
    "    # Train and test scores\n",
    "    y_train_pred = model.predict(X_train_selected)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "    y_test_pred = model.predict(X_test_selected)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"threshold\": threshold,\n",
    "        \"n_features\": len(selected_indices),\n",
    "        \"train r2\": train_r2,\n",
    "        \"test r2\": test_r2,\n",
    "        \"train mse\": train_mse,\n",
    "        \"test mse\": test_mse,\n",
    "        \"selected_features\": lasso_threshold_selected_names\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "# print(results_df)\n",
    "\n",
    "#  find the best threshold based on train mse\n",
    "best_row = results_df.loc[results_df['train mse'].idxmin()]\n",
    "print(\"\\nBest Threshold (by training MSE):\")\n",
    "print(best_row)\n",
    "\n",
    "# after finding best_row\n",
    "print(\"\\n Selected Features at Best Threshold:\")\n",
    "for name in best_row['selected_features']:\n",
    "    print(\" -\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de0461",
   "metadata": {},
   "source": [
    "The best model based on test R² was obtained using a coefficient threshold of approximately 1.89, which retained 29 features after thresholding. This model achieved a training R² of 0.794 and a test R² of 0.784, corresponding to training MSE = 58.05 and test MSE = 56.90.\n",
    "\n",
    "Compared to the original Lasso model without thresholding, this model shows improved generalization performance, as indicated by the higher test R². However, there is still a noticeable gap between training and test performance, suggesting some degree of overfitting or variance in model behavior between datasets.\n",
    "\n",
    "To better understand how model complexity affects generalization, we will visualize the R² gap between training and testing across different thresholds in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# R²\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results_df['threshold'], results_df['train r2'], label='Train R²', marker='o')\n",
    "plt.plot(results_df['threshold'], results_df['test r2'], label='Test R²', marker='s')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Train vs Test R² by Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# MSE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(results_df['threshold'], results_df['train mse'], label='Train MSE', marker='o')\n",
    "plt.plot(results_df['threshold'], results_df['test mse'], label='Test MSE', marker='s')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Train vs Test MSE by Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf52100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the R² and MSE gap\n",
    "results_df['r2 gap'] = np.abs(results_df['train r2'] - results_df['test r2'])\n",
    "results_df['mse gap'] = np.abs(results_df['train mse'] - results_df['test mse'])\n",
    "\n",
    "# find the threshold with the smallest MSE gap\n",
    "most_generalizable_mse = results_df.loc[results_df['mse gap'].idxmin()]\n",
    "\n",
    "# after finding most generalizable mse\n",
    "\n",
    "print(\"\\nThreshold with smallest Train-Test mse gap:\")\n",
    "print(most_generalizable_mse)\n",
    "\n",
    "smallest_mse_gap_features = [name for name in most_generalizable_mse['selected_features']]\n",
    "print(\"\\nSelected Features at Smallest MSE Gap:\", smallest_mse_gap_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b89b03",
   "metadata": {},
   "source": [
    "Performance Summary:\n",
    "\n",
    "The best test R² was achieved at a threshold of ~2,45, with a test R² of 0.784, train R² of 0.794, and 29 features selected.\n",
    "The smallest R² gap (between train and test) occurred at threshold ≈ 2.45, with: \n",
    "Train R² = 0.7940,\n",
    "Test R² = 0.7830,\n",
    "R² gap = 0.011,\n",
    "The smallest MSE gap was found at threshold ≈ 2.45, where:\n",
    "Train MSE = 57.73, \n",
    "Test MSE = 57.25, \n",
    "MSE gap = 0.48.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Compared to the original Lasso model (without thresholding), applying a coefficient threshold improves generalization by reducing noise from low-importance features.\n",
    "As shown in the R² and MSE plots, increasing the threshold gradually reduces overfitting (smaller train-test gap), up to a point.\n",
    "However, too high a threshold (>2.45) leads to performance breakdown. It can be seen from the plot R² drops sharply and MSE spikes, due to excessive feature elimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf304b0",
   "metadata": {},
   "source": [
    "feature comparison from forward step, lasso, lasso with threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b39d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to set conversion for feature comparison\n",
    "set_lasso = set(lasso_selected_features)\n",
    "set_thresh = set(smallest_mse_gap_features)\n",
    "set_forward = set(forward_selected_names)\n",
    "\n",
    "\n",
    "# common features\n",
    "common_all = set_lasso & set_thresh & set_forward\n",
    "print(f\" Features selected by ALL methods:\\n{common_all}\", f\"\\n with\" , len(common_all), \"features\")\n",
    "\n",
    "# two-way intersections\n",
    "print(f\"\\n Lasso ∩ Threshold:\\n{set_lasso & set_thresh}\", f\"\\n with\" , len(set_lasso & set_thresh), \"features\")\n",
    "print(f\"\\n Lasso ∩ Forward:\\n{set_lasso & set_forward}\", f\"\\n with\" , len(set_lasso & set_forward), \"features\")\n",
    "print(f\"\\n Threshold ∩ Forward:\\n{set_thresh & set_forward}\", f\"\\n with\" , len(set_thresh & set_forward), \"features\"   )\n",
    "\n",
    "# Specific features only in one method\n",
    "print(f\"\\n Only in Lasso:\\n{set_lasso - set_thresh - set_forward}\", f\"\\n with\" , len(set_lasso - set_thresh - set_forward), \"features\")\n",
    "print(f\"\\n Only in Thresholding:\\n{set_thresh - set_lasso - set_forward}\", f\"\\n with\" , len(set_thresh - set_lasso - set_forward), \"features\")\n",
    "print(f\"\\n Only in Forward Stepwise:\\n{set_forward - set_lasso - set_thresh}\", f\"\\n with\" , len(set_forward - set_lasso - set_thresh), \"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d33e2f",
   "metadata": {},
   "source": [
    "### 3.4. Tree-based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dea000",
   "metadata": {},
   "source": [
    "#### 1. Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef16ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + \"/opt/homebrew/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a regression tree on the training data using the mse metric for splitting, considering all the features and splitting if there are more than 10 samples at a node.\n",
    "tree = DecisionTreeRegressor(criterion='squared_error', max_features=None, min_samples_split=20)\n",
    "\n",
    "tree_est = tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the tree with the help of the graphviz and the iPython package\n",
    "# use sklearn's export to generate the dot-data string file with all the nodes and their props.\n",
    "dot_data = export_graphviz(tree_est, out_file='boston_tree.dot',feature_names=concrete_df.columns[0:-1],filled=True, \n",
    "                           rounded=True, special_characters=True)\n",
    "\n",
    "with open('boston_tree.dot') as f:\n",
    "    dot_graph = f.read()  \n",
    "\n",
    "# create the source object\n",
    "I = graphviz.Source(dot_graph, format='png', engine='dot')\n",
    "# Use ipython Image to shrink the rendered image of the source obj to fit into jupyter nb.\n",
    "Image(I.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b97c03",
   "metadata": {},
   "source": [
    "Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e12493",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_est.predict(X_test)\n",
    "\n",
    "print(\"R² Score on Test Set:\", r2_score(y_test, y_pred))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cdde8",
   "metadata": {},
   "source": [
    "Model optimization\n",
    "\n",
    "Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(data=tree.feature_importances_, index=list(concrete_df.columns[0:-1]))\n",
    "feature_importances.sort_values(axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b93f05",
   "metadata": {},
   "source": [
    "| Feature                                                   | Importance | Meaning                                                                                                                                             |\n",
    "| --------------------------------------------------------- | ---------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Age (day)**                                             | 0.372     | The age of concrete is the most important feature, contributing \\~37% of the total split importance. It heavily influences the strength prediction. |\n",
    "| **Cement (component 1)(kg in a m^3 mixture)**             | 0.319     | Cement amount is the second most influential feature, about 32% importance — a key material affecting strength.                                     |\n",
    "| **Water (component 4)(kg in a m^3 mixture)**              | 0.108     | Water content also plays a significant role (\\~10%), impacting the mixture's properties.                                                            |\n",
    "| **Superplasticizer (component 5)(kg in a m^3 mixture)**   | 0.095     | Superplasticizer's role is noticeable (\\~9.5%), affecting workability and strength.                                                                 |\n",
    "| **Blast Furnace Slag (component 2)(kg in a m^3 mixture)** | 0.056     | Moderately important (\\~5.5%), influencing the final properties.                                                                                    |\n",
    "| **Fly Ash (component 3)(kg in a m^3 mixture)**            | 0.022     | Low importance (\\~2.2%), minor influence on predictions.                                                                                            |\n",
    "| **Fine Aggregate (component 7)(kg in a m^3 mixture)**     | 0.017     | Minimal contribution (\\~1.7%).                                                                                                                      |\n",
    "| **Coarse Aggregate (component 6)(kg in a m^3 mixture)**   | 0.012     | Smallest importance (\\~1.2%), less relevant in this model.                                                                                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa31c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = tree_est.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(importances)), feature_names[indices], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d18ed1",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced01293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# Define the hyperparameters grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, 15, None],\n",
    "    'min_samples_split': [2, 10, 20, 50],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2'] \n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree,\n",
    "    param_grid=param_grid,\n",
    "    cv=kf,                # 10-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',  # Use negative MSE as scoring metric\n",
    "    n_jobs=-1,           # Use all CPU cores\n",
    "    verbose=1            # Print progress\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator for prediction\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test set MSE: {mse:.4f}\")\n",
    "print(f\"Test set R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train the optimized tree\n",
    "optimized_tree = DecisionTreeRegressor(\n",
    "    max_depth=10,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=10,\n",
    "    random_state=0\n",
    ")\n",
    "optimized_tree.fit(X_train, y_train)\n",
    "\n",
    "# 2. Export the tree to DOT format\n",
    "dot_data = export_graphviz(\n",
    "    optimized_tree,\n",
    "    out_file=None,\n",
    "    feature_names=concrete_df.columns[:-1],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "# 3. Render and display using graphviz\n",
    "graph = graphviz.Source(dot_data, format='png')\n",
    "Image(graph.render('optimized_tree'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3523b",
   "metadata": {},
   "source": [
    "Pruning (Cost-Complexity pruning): select a subtree leading to the lowest test error rate.\n",
    "\n",
    "Motivation: \n",
    "- ccp_alpha is a regularization hyperparameter, increasing it prunes more, reducing overfitting.\n",
    "- We have already got a strong performance (R² ≈ 0.8055), and pruning it can imporve generalization further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a full tree\n",
    "path = DecisionTreeRegressor(random_state=0).cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Optionally reduce the number of alphas (too many can slow down grid search)\n",
    "ccp_alphas = np.unique(np.round(ccp_alphas, 4))  # Remove tiny variations\n",
    "ccp_alphas = ccp_alphas[::5]  # Sample every 5th alpha if too many\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdff134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'ccp_alpha': ccp_alphas  # ← added\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "grid = GridSearchCV(tree, param_grid, cv=kf, scoring='r2', n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate and visualize\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "\n",
    "best_tree = grid.best_estimator_\n",
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "print(\"Test set MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Test set R²:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7af295b",
   "metadata": {},
   "source": [
    "Interpretation of Final Model Results:\n",
    "- Best Hyperparameters (with pruning):\n",
    "    - ccp_alpha = 0.0689\n",
    "    - max_depth = 10\n",
    "    - max_features: None\n",
    "    - min_samples_leaf = 1\n",
    "    - min_samples_spilit = 2\n",
    "- Test Set Performance:\n",
    "    - MSE: ≈ 56.2, which is still very low\n",
    "    - R²: ≈ 0.787, it is still very solid fit (explains ~78.7% of variance)\n",
    "- Pruning Effect:\n",
    "    - The ccp_alpha = 0.0689 suggests aggressive pruning helped generalize better.\n",
    "    - The earlier R² was ≈ 0.7815 without pruning, so pruning leads to a higher R² and a **simpler, more generalizable tree**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90ea4f",
   "metadata": {},
   "source": [
    "pruned tree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3697aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fit the optimized and pruned tree\n",
    "final_tree = DecisionTreeRegressor(\n",
    "    max_depth=10,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=10,\n",
    "    ccp_alpha=0.2008,\n",
    "    random_state=0\n",
    ")\n",
    "final_tree.fit(X_train, y_train)\n",
    "\n",
    "# 2. Export to DOT format\n",
    "dot_data = export_graphviz(\n",
    "    final_tree,\n",
    "    out_file=None,\n",
    "    feature_names=X.columns if hasattr(X, 'columns') else [f\"X{i}\" for i in range(X.shape[1])],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "# 3. Render with graphviz\n",
    "tree_graph = graphviz.Source(dot_data, format=\"png\")\n",
    "tree_graph.render(\"final_pruned_tree\", cleanup=True)\n",
    "Image(\"final_pruned_tree.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded31776",
   "metadata": {},
   "source": [
    "Model Evaluation & Diagonistic Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e91f8",
   "metadata": {},
   "source": [
    "Residual Analysis (difference between actual and predicted values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals, edgecolor='k', facecolor='none')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec8302",
   "metadata": {},
   "source": [
    "Parity Plot (checks how close predictions are to actual values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48087b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, edgecolor='k', facecolor='none')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Ideal line\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a04c4",
   "metadata": {},
   "source": [
    "Model Complexity Check - check if the tree is too deep or has too many leaves. A very large tree usually overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813caf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Tree depth:\", final_tree.get_depth())\n",
    "print(\"Number of leaves:\", final_tree.get_n_leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c12a4",
   "metadata": {},
   "source": [
    "check Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_train_pred = final_tree.predict(X_train)\n",
    "y_test_pred = final_tree.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train R²: {train_r2:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")\n",
    "print(f\"Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2d7bf",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "The model fits the training data very well but is less accurate on new data, indicating some degree of overfitting, but not severe.\n",
    "\n",
    "The gap between train and test metrics has reduced compared to the previous attempts, so this model generalizes better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccc0cc",
   "metadata": {},
   "source": [
    "#### 2. Bagging and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [50, 100, 200, 300, 500]:\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state=0, oob_score=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{n} trees - OOB Score: {model.oob_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f6598",
   "metadata": {},
   "source": [
    "from the result, we can see that the OOB Score of 200 trees is the best, which means it saves training time and is more efficient. Then perform by buding a bagged ensemble using 200 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a009109",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagger = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    criterion='squared_error',         \n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "bag_est = bagger.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abd9d5",
   "metadata": {},
   "source": [
    "Compute the test MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffc60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bag_est.predict(X_test)\n",
    "\n",
    "print(\"Test MSE = \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9b2a9",
   "metadata": {},
   "source": [
    "Visualize the test MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted vs the actual medv response\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "ax.scatter(y_pred, y_test, facecolor='None', edgecolor='b')\n",
    "# add a reference unity line\n",
    "ax.plot([min(y_pred), max(y_pred)], [min(y_test), max(y_test)], linestyle='--', color='k');\n",
    "ax.set_xlabel('y_predicted')\n",
    "ax.set_ylabel('y_actual')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e9bfb",
   "metadata": {},
   "source": [
    "build a random forest and fit it to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550abe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators=200, criterion='squared_error', max_features=4, bootstrap=True, \n",
    "                               oob_score=True, random_state=0 )\n",
    "\n",
    "forest_est = forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97282fef",
   "metadata": {},
   "source": [
    "Compute the test MSE of the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest_est.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Test MSE =', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e9ded",
   "metadata": {},
   "source": [
    "Interpretation: \n",
    "\n",
    "| Model         | Description                              | Test MSE    |\n",
    "| ------------- | ---------------------------------------- | ----------- |\n",
    "| Bagging       | Uses all features, averages many trees   | 19.86       |\n",
    "| Random Forest | Random subset of features for each split | **19.80**  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed200c4",
   "metadata": {},
   "source": [
    "Random Forest introduces feature randomness (via max_features) to decorrelate trees more than standard bagging. So in this case, random Forest is an improved version of Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652c7a7",
   "metadata": {},
   "source": [
    "Model Refinement - Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the feature importances\n",
    "feature_importances = pd.Series(data=forest_est.feature_importances_, index=list(concrete_df.columns[0:-1]))\n",
    "feature_importances = feature_importances.sort_values(axis=0, ascending=False)\n",
    "feature_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(importances)), feature_names[indices], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eec63a",
   "metadata": {},
   "source": [
    "After fitting the Random Forest model, the feature importance analysis reveals which input variables most strongly influence the prediction. The feature **“Age”** is the most important, indicating it has the greatest impact on the concrete strength. **“Cement content”** follows as the second most influential feature. Other components like **Water, Superplasticizer, and Blast Furnace Slag** contribute moderately, while features such as **Fly Ash** have relatively low importance.\n",
    "\n",
    "This insight helps to understand the key factors driving the model’s predictions, supports domain knowledge validation, and can guide feature selection or further data collection efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0916303",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all feature names in order, matching X_train columns\n",
    "feature_names = [\n",
    "    'Cement (component 1)(kg in a m^3 mixture)', \n",
    "    'Blast Furnace Slag (component 2)(kg in a m^3 mixture)', \n",
    "    'Fly Ash (component 3)(kg in a m^3 mixture)', \n",
    "    'Water  (component 4)(kg in a m^3 mixture)', \n",
    "    'Superplasticizer (component 5)(kg in a m^3 mixture)', \n",
    "    'Coarse Aggregate  (component 6)(kg in a m^3 mixture)', \n",
    "    'Fine Aggregate (component 7)(kg in a m^3 mixture)', \n",
    "    'Age (day)'\n",
    "]\n",
    "\n",
    "# Top features to keep\n",
    "top_features = [\n",
    "    'Age (day)', \n",
    "    'Cement (component 1)(kg in a m^3 mixture)', \n",
    "    'Water  (component 4)(kg in a m^3 mixture)', \n",
    "    'Superplasticizer (component 5)(kg in a m^3 mixture)', \n",
    "    'Blast Furnace Slag (component 2)(kg in a m^3 mixture)'\n",
    "]\n",
    "\n",
    "# Get their column indices\n",
    "top_indices = [feature_names.index(f) for f in top_features]\n",
    "\n",
    "# Select columns by index\n",
    "X_train_reduced = X_train[:, top_indices]\n",
    "X_test_reduced = X_test[:, top_indices]\n",
    "\n",
    "# Train the model on reduced features\n",
    "model_reduced = RandomForestRegressor(random_state=42)\n",
    "model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_reduced = model_reduced.predict(X_test_reduced)\n",
    "print(\"Test R²:\", r2_score(y_test, y_pred_reduced))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, y_pred_reduced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc098cab",
   "metadata": {},
   "source": [
    "Using only the top 5 important features improved the model’s generalization and reduced noise from less relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a34f2",
   "metadata": {},
   "source": [
    "Model Optimization - Hyperparameter Tuning for Random Forest using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a2fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=kf, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"Test R²:\", r2_score(y_test, y_pred))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8ae4b",
   "metadata": {},
   "source": [
    "Test R² improved slightly to ~0.92 (from 0.9205 before)\n",
    "\n",
    "Test MSE decreased to ~20.64 (from 20.94 before)\n",
    "\n",
    "This means the model’s performance got a bit better — more accurate and slightly more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf6e3d",
   "metadata": {},
   "source": [
    "Model evaluation and diagnostic checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd9f29",
   "metadata": {},
   "source": [
    "Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(y_pred, residuals, alpha=0.6, edgecolors='k')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals (True - Predicted)')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246322f",
   "metadata": {},
   "source": [
    "Out-Of-Bag (OOB) Error: We would like to set oob_score=True when creating RandomForestRegressor, and the model will estimate error internally using samples not used in each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdfa0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train model with OOB enabled\n",
    "rf_oob = RandomForestRegressor(n_estimators=200, max_depth=best_rf.max_depth,\n",
    "                               max_features=best_rf.max_features,\n",
    "                               random_state=0, oob_score=True)\n",
    "rf_oob.fit(X_train, y_train)\n",
    "\n",
    "print(f\"OOB R² score: {rf_oob.oob_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc660c",
   "metadata": {},
   "source": [
    "OOB score being close to the test R² (~0.92) confirms the train-test split results are reliable and not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226bc730",
   "metadata": {},
   "source": [
    "#### 3. Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1775d5",
   "metadata": {},
   "source": [
    "creating and training a Gradient Boosting Regressor model on the traning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = GradientBoostingRegressor(\n",
    "    loss='squared_error',        \n",
    "    learning_rate=0.01,          \n",
    "    n_estimators=200,            \n",
    "    max_depth=3,                 \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "boost_est = booster.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fceaf7",
   "metadata": {},
   "source": [
    "Make predictions on the test set and evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31726856",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = boost_est.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d9221b",
   "metadata": {},
   "source": [
    "feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(data=boost_est.feature_importances_, index=list(concrete_df.columns[:-1]))\n",
    "sorted_feature_importances = feature_importances.sort_values(ascending=False)\n",
    "sorted_feature_importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e4b96",
   "metadata": {},
   "source": [
    "The Gradient Boosting model identifies **\"Age\"** and **\"Cement\"** as the most influential factors in predicting the target variable, indicating these features have the strongest impact on the model’s predictions. Other features like **\"Superplasticizer\"** and **\"Water\"** also contribute notably but to a lesser degree. Features such as **\"Coarse Aggregate\"** and **\"Fly Ash\"** show minimal influence, suggesting they play a minor role in the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560d272",
   "metadata": {},
   "source": [
    "Partial dependence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idxs = np.argsort(feature_importances.values)[-3:]\n",
    "\n",
    "# Plot PDP\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    boost_est,                  \n",
    "    X_train,                    \n",
    "    features=feature_idxs,      \n",
    "    feature_names=feature_importances.index.tolist(),\n",
    "    ax=ax\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b71289",
   "metadata": {},
   "source": [
    "There might be an optimal range for **superplasticizer** where its positive effect on the predicted outcome is most pronounced, and further increases might not be beneficial. For **Cement**, the \"steps\" could suggest that the model has specific \"regimes\" or thresholds for cement content where the properties change significantly. Higher cement content generally leads to a better (higher) predicted outcome, but these improvements might not be linear. The plot of **Age**  implies that the most significant improvements in the predicted outcome due to aging occur within the first couple of months. Beyond this initial period, further aging has a negligible additional impact on the predicted outcome. This could indicate a saturation point where the material's properties stabilize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d1ea3",
   "metadata": {},
   "source": [
    "Model refinement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ac5b8",
   "metadata": {},
   "source": [
    "**Feature Selection** by keeping only the most important features based on the gradient boosting feature importances.\n",
    "From the results, the most important features are: Age, Cement, Superplasticizer, water and Blast Furnance Slag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [\n",
    "    'Age (day)',\n",
    "    'Cement (component 1)(kg in a m^3 mixture)',\n",
    "    'Superplasticizer (component 5)(kg in a m^3 mixture)',\n",
    "    'Water  (component 4)(kg in a m^3 mixture)',\n",
    "    'Blast Furnace Slag (component 2)(kg in a m^3 mixture)'\n",
    "]\n",
    "\n",
    "X_selected = concrete_df[important_features]\n",
    "y = concrete_df['Concrete compressive strength(MPa, megapascals)']  # Replace 'target_column' with your target variable column name\n",
    "\n",
    "X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=0)\n",
    "\n",
    "booster_sel = GradientBoostingRegressor(\n",
    "    loss='squared_error',        # corrected here\n",
    "    learning_rate=0.001,\n",
    "    n_estimators=5000,\n",
    "    max_depth=4,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "boost_est_sel = booster_sel.fit(X_train_sel, y_train_sel)\n",
    "\n",
    "y_pred_sel = boost_est_sel.predict(X_test_sel)\n",
    "mse_sel = mean_squared_error(y_test_sel, y_pred_sel)\n",
    "print(\"Test MSE with selected features:\", mse_sel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1e4a2",
   "metadata": {},
   "source": [
    "Feature selection focusing on PDP results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features strongly supported by PDP interpretation\n",
    "important_features_pdp = [\n",
    "    'Age (day)',\n",
    "    'Cement (component 1)(kg in a m^3 mixture)',\n",
    "    'Superplasticizer (component 5)(kg in a m^3 mixture)'\n",
    "]\n",
    "\n",
    "X_selected_pdp = concrete_df[important_features_pdp]\n",
    "y = concrete_df['Concrete compressive strength(MPa, megapascals)']\n",
    "\n",
    "\n",
    "# Set up the gradient boosting regressor with early stopping\n",
    "booster_sel = GradientBoostingRegressor(\n",
    "    loss='squared_error',\n",
    "    learning_rate=0.01,      \n",
    "    n_estimators=1000,       \n",
    "    max_depth=4,\n",
    "    random_state=0,\n",
    "    validation_fraction=0.1, \n",
    "    n_iter_no_change=50,  \n",
    "    tol=1e-4\n",
    ")\n",
    "\n",
    "# Fit model with early stopping\n",
    "boost_est_sel = booster_sel.fit(X_train_sel, y_train_sel)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_sel = boost_est_sel.predict(X_test_sel)\n",
    "mse_sel = mean_squared_error(y_test_sel, y_pred_sel)\n",
    "\n",
    "print(\"Test MSE with PDP-based selected features:\", mse_sel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edd40f",
   "metadata": {},
   "source": [
    "Interpretation: The dropped features might still contain some usefull inforamtion, even if their importance seemed slow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7246cb3",
   "metadata": {},
   "source": [
    "Model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375a892",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for GradientBoostingRegressor using RandomizedSearchCV: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb82ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,           # number of parameter settings sampled\n",
    "    cv=kf,                # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',  # minimize MSE\n",
    "    n_jobs=-1,           # use all cores\n",
    "    random_state=0,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the random search to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_booster = random_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = best_booster.predict(X_test)\n",
    "\n",
    "# Calculate MSE and R2 score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test R2 score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68bd872",
   "metadata": {},
   "source": [
    "The Gradient Boosting model uses carefully chosen hyperparameters to balance accuracy and generalization. It builds 500 trees with a maximum depth of 4, limiting complexity to avoid overfitting. Each tree is trained on 60% of the data and considers only a subset of features at each split, adding randomness to improve robustness. Minimum samples per split and leaf prevent overly specific rules, while a learning rate of 0.1 ensures gradual, stable learning. Overall, these settings help the model perform well on unseen data while avoiding overfitting. The tuned Gradient Boosting model shows strong predictive performance, achieving a low test MSE of 17.38 and a high R² of 0.93."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4385949",
   "metadata": {},
   "source": [
    "Model evaluation and diagnostic checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0597669",
   "metadata": {},
   "source": [
    "Residual Analysis: check if errors are randomly distributed and there's no systematic bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbe7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_pred, residuals, edgecolor='k', facecolor='none')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90485c45",
   "metadata": {},
   "source": [
    "The residual plot shows that the residuals are evenly scattered around zero without any clear pattern, indicating that the model's errors are randomly distributed. The consistent spread of residuals suggests that the assumption of constant variance is met, and although there are a few isolated outliers, they do not undermine the overall fit. This implies that the model captures the data well, with no strong bias or missed nonlinear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53afb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, edgecolor='k', facecolor='none')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509256d",
   "metadata": {},
   "source": [
    "Train vs. Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042435d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# R²\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# RMSE\n",
    "rmse_train = root_mean_squared_error(y_train, y_train_pred)\n",
    "rmse_test =root_mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train R²: {r2_train:.3f}, Test R²: {r2_test:.3f}\")\n",
    "print(f\"Train RMSE: {rmse_train:.3f}, Test RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db0d584",
   "metadata": {},
   "source": [
    "The gradient boosting model shows excellent fit on training data and still performs very well on test data. The performance drop is moderate and expected in real-world modeling. There is no strong evidence of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753e25b",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74708af",
   "metadata": {},
   "source": [
    "In this study, we explored the relationships between the composition of concrete mixtures and their corresponding compressive strength through data-driven analysis. \n",
    "\n",
    "In **Chapter 1**, the problem under discussion is introduced and the objective of the study is defined.\n",
    "\n",
    "A concise explanation of the dataset is provided in **Chapter 2**, along with information on its availability.\n",
    "\n",
    "The data preprocessing phase, as discussed in **Chapter 3**, included standardization and feature engineering particularly the creation of the water-binder ratio and logarithmic age transformation, which helped reveal non-linear effects and improved model performance. Visual exploration and correlation analysis indicated that water content negatively affects strength, aligning with established domain knowledge such as the Abrams' law.\n",
    "\n",
    "**not done yet**\n",
    "\n",
    "Several regression models were in **Chapter 4** evaluated, including Linear Regression, Decision Trees, and ensemble methods. Among them, tree-based models demonstrated superior performance in capturing complex, non-linear interactions between variables. The results suggest that robust, assumption-light models are better suited for this dataset due to the irregular and skewed distribution of target values.\n",
    "\n",
    "Overall, this analysis provides valuable insights into the importance of feature interactions in predicting concrete strength and highlights the potential of machine learning methods in advancing material design and quality control.\n",
    "\n",
    "Compare …, the best result is from….\n",
    "\n",
    "The most important features\n",
    "\n",
    "What could have done, if we had more time on this project\n",
    "("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

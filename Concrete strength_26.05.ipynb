{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0190fded-5804-4fec-824e-664c3db81c9d",
      "metadata": {
        "id": "0190fded-5804-4fec-824e-664c3db81c9d"
      },
      "source": [
        "# **Predicting Concrete Compressive Strength**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "927116cb-12cc-4c5e-96e3-05583307ab34",
      "metadata": {
        "id": "927116cb-12cc-4c5e-96e3-05583307ab34"
      },
      "source": [
        "### Motivation:\n",
        "Concrete is a fundamental material in civil engineering. Its compressive strength is important for ensuring the safety and durability of structures. However, determining this strength accurately is challenging because it depends on a nonlinear function between several factors, including the age of the concrete and the proportions of its componentsâ€”such as cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, and fine aggregate.\n",
        "This project aims to apply machine learning techniques to improve the prediction of concrete strength, in order to contribute to better design, quality control, and resource optimization in construction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2383ccde-4789-4114-99e4-58649a870fa4",
      "metadata": {
        "id": "2383ccde-4789-4114-99e4-58649a870fa4"
      },
      "source": [
        "### Dataset Explanation:\n",
        "The dataset is sourced from the UCI Machine Learning Repository and contains 1030 observations with 8 quantitative input variables, and 1 quantitative output variable.\n",
        "The input variables are: cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, fine aggregate and age. Except for age, the other variables are ingredient quantities in the concrete mixture and measured in *kg in a $m^{3}$* mixture. The age is measured in *days*.\n",
        "The target, concrete compressive strengt, is measured in *MPa*."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6142253a-0d1a-4536-9cc5-cc866ec2ac83",
      "metadata": {
        "id": "6142253a-0d1a-4536-9cc5-cc866ec2ac83"
      },
      "source": [
        "### Data Analytics: Preprocessing\n",
        "Since there is no missing attribute values according to the information provided by UCI Machine Learning Repository. Data can be directly read from Concrete_data.csv."
      ]
    },
    {
      "cell_type": "code",
      "id": "fb071974-026d-4697-9690-3ed22b465284",
      "metadata": {
        "id": "fb071974-026d-4697-9690-3ed22b465284"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import sklearn\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "from itertools import combinations\n",
        "\n",
        "from statsmodels.stats.outliers_influence import OLSInfluence\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, make_scorer, r2_score\n",
        "\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "sns.set_style(\"darkgrid\")\n",
        "# print numpy arrays with precision 4\n",
        "np.set_printoptions(precision=4)"
      ]
    },
    {
      "cell_type": "code",
      "id": "c5280c72-0c39-4730-b6ec-60bbc2ef37c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "executionInfo": {
          "elapsed": 53,
          "status": "ok",
          "timestamp": 1748382265237,
          "user": {
            "displayName": "Luying Hua",
            "userId": "04014220315073922395"
          },
          "user_tz": -120
        },
        "id": "c5280c72-0c39-4730-b6ec-60bbc2ef37c4",
        "outputId": "27b0314d-95fc-43c3-ed2a-65ee35eae746"
      },
      "source": [
        "concrete_df = pd.read_csv('./Concrete_Data.csv')\n",
        "concrete_df.columns = concrete_df.columns.str.strip()\n",
        "concrete_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "36782121-6a11-4d5c-9d2f-bad049c3e982",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "executionInfo": {
          "elapsed": 72,
          "status": "error",
          "timestamp": 1748382282175,
          "user": {
            "displayName": "Luying Hua",
            "userId": "04014220315073922395"
          },
          "user_tz": -120
        },
        "id": "36782121-6a11-4d5c-9d2f-bad049c3e982",
        "outputId": "4c41f0fc-1eb5-4880-f311-98760eda4ea3"
      },
      "source": [
        "#define all the variables we need for the linear regression with concrete compressive strength as response and all other variables as possible features\n",
        "label_column = 'concrete_compressive_strength'\n",
        "feature_columns = [c for c in concrete_df.columns if c != label_column]\n",
        "X = concrete_df[feature_columns].values\n",
        "y = concrete_df[label_column].values\n",
        "p = len(feature_columns)\n",
        "print(\"Features are:\", feature_columns,\n",
        "      \", and the response variable is:\", label_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e18e9dc-e27b-45f0-bc16-3bc41f377da1",
      "metadata": {
        "id": "6e18e9dc-e27b-45f0-bc16-3bc41f377da1"
      },
      "source": [
        "#### Explanation of relevant variables:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add94d5a-0be7-4a1a-a87e-f3a29608bc48",
      "metadata": {
        "id": "add94d5a-0be7-4a1a-a87e-f3a29608bc48"
      },
      "source": [
        "The following table shows the meaning and expected effect of respective variables on strength.\n",
        "| Variable             | Meaning                              | Expected Effect on Strength    |\n",
        "| -------------------- | ------------------------------------ | ------------------------------ |\n",
        "| `cement`             | Binder                               | increases strength          |\n",
        "| `blast_furnace_slag` | Supplementary binder                 | increases strength or neutral                  |\n",
        "| `fly_ash`            | Supplementary binder                 | increase strength or neutral                  |\n",
        "| `water`              | Affects workability and hydration    | decreases strength (excess) |\n",
        "| `superplasticizer`   | Increases workability, reduces water | increase or decrease depending on context  |\n",
        "| `coarse_aggregate`   | Filler                               | neutral or mild effect         |\n",
        "| `fine_aggregate`     | Filler                               | neutral or mild effect         |\n",
        "| `age`                | Curing time                          | increases strength          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6faa99d-e1e4-4c2f-b75f-40e963f83c13",
      "metadata": {
        "id": "e6faa99d-e1e4-4c2f-b75f-40e963f83c13"
      },
      "source": [
        "#### Correlation between relevant variables:"
      ]
    },
    {
      "cell_type": "code",
      "id": "43ae9180-97fc-4e43-9aea-00cc84ff3126",
      "metadata": {
        "id": "43ae9180-97fc-4e43-9aea-00cc84ff3126",
        "outputId": "32c3283b-094a-4773-b2da-4d787f65f665"
      },
      "source": [
        "corr = concrete_df.corr(numeric_only=True)\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8420141-c9ca-414a-89f8-a08550c534b7",
      "metadata": {
        "id": "e8420141-c9ca-414a-89f8-a08550c534b7"
      },
      "source": [
        "#### Variables that influence concrete strength:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f3d5b1-6386-4095-9180-a8d3092ddd3d",
      "metadata": {
        "id": "73f3d5b1-6386-4095-9180-a8d3092ddd3d"
      },
      "source": [
        "According to the result of the heatmap, it can be seen that **cement** has a moderately strong positive correlation with concrete strength with a value of +0.50, which indicates more cement usually leads to stronger concrete. **Superplasticizer** also has a positive effect with a value of +0.37.\n",
        "**Age** has a positive effect too , because concrete gets stronger over time.\n",
        "**Water** has a negative correlation with strength of -0.29, which means more water tends to weaken concrete. This observation is consistent with **Abrams' water-to-cement ratio pronouncement**, which emphasizes that increased water relative to cement typically reduces concrete strength."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5a3353-f378-47c8-a38d-ed03b34d03d8",
      "metadata": {
        "id": "9b5a3353-f378-47c8-a38d-ed03b34d03d8"
      },
      "source": [
        "#### Multicollinearity:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17706878-5c60-444b-933b-e9476b2d19cd",
      "metadata": {
        "id": "17706878-5c60-444b-933b-e9476b2d19cd"
      },
      "source": [
        "The highest multicollinearity is the correlation between **water and superplasticizer**, which has a value of -0.66. This indicates they carry overlapping and opposite information. There is also moderate correlation among **cement**, **blast furnace slag**, and **fly ash** because these may act as partial substitutes in the concrete mix, so they tend to move in opposite directions."
      ]
    },
    {
      "cell_type": "code",
      "id": "fdcbdc69-5325-4790-879f-451bd37f29ff",
      "metadata": {
        "id": "fdcbdc69-5325-4790-879f-451bd37f29ff",
        "outputId": "93372648-841a-4f1f-af6e-9b0892e57bba"
      },
      "source": [
        "VIFs = [(predictor, variance_inflation_factor(X,_)) \\\n",
        "        for _,predictor in enumerate(list(feature_columns))]\n",
        "print('Variance Inflation Factors')\n",
        "for tup in VIFs:\n",
        "    print('{:20}'.format(tup[0]), '{:.3f}'.format(tup[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9edd83c-d640-43fd-b67f-4e76bcb42ac4",
      "metadata": {
        "id": "b9edd83c-d640-43fd-b67f-4e76bcb42ac4"
      },
      "source": [
        "The variance inflation factors are larger for cement, blast furnace slag, fly ash, water, coarse aggregate, fine aggregate. This also indicates multi-collinearity of the factors mention above.\n",
        "\n",
        "As mentioned in the lecture content of **MLDA**, VIF equal to 1 shows the absence of collinearity Usually, there is collinearity when VIF is larger than 5."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9539ce69-41fa-4218-a268-242147cc9d83",
      "metadata": {
        "id": "9539ce69-41fa-4218-a268-242147cc9d83"
      },
      "source": [
        "### Machine Learning Methods:\n",
        "This project aims to predict concrete compressive strength which is a problem with a quantitative response. According to the lecture content in the fundamental part of Machine Learning and Data Analytics(MLDA), this task is a **regression task**. In the following part, linear regression, ridge regression, lasso regression, one decision-tree based method are applied."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "950c77ad-6c6c-4817-b9d9-5f8dfb51fc93",
      "metadata": {
        "id": "950c77ad-6c6c-4817-b9d9-5f8dfb51fc93"
      },
      "source": [
        "### Cross validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a12737-156b-4734-8418-3efea661a73c",
      "metadata": {
        "id": "26a12737-156b-4734-8418-3efea661a73c"
      },
      "source": [
        "#### K-fold cross validation:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69fb05e9-9d86-49d6-9abb-a3009d0f959e",
      "metadata": {
        "id": "69fb05e9-9d86-49d6-9abb-a3009d0f959e"
      },
      "source": [
        "For supervised machine learning, the goal is to develop a model that can perform accurately not only on the data it was trained on, but also on previously unseen data. To evaluate a model's generalization ability, the **K-fold** method is utilized as the cross validation method."
      ]
    },
    {
      "cell_type": "code",
      "id": "61ec3953-992d-4cef-aeee-0249bb12fd4d",
      "metadata": {
        "id": "61ec3953-992d-4cef-aeee-0249bb12fd4d"
      },
      "source": [
        "# define the kfold, shuffle the training and test dataset every time\n",
        "kf = KFold(n_splits=10, random_state = 0, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d984cde4-d440-47b9-a258-0ddc16ef9eb5",
      "metadata": {
        "id": "d984cde4-d440-47b9-a258-0ddc16ef9eb5"
      },
      "source": [
        "##### Scores for the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbcce5b-eca0-49df-82eb-3407024b6a17",
      "metadata": {
        "id": "4bbcce5b-eca0-49df-82eb-3407024b6a17"
      },
      "source": [
        "Mean squared error:"
      ]
    },
    {
      "cell_type": "code",
      "id": "63c4433d-cbf9-4022-81b0-5c90c22ece83",
      "metadata": {
        "id": "63c4433d-cbf9-4022-81b0-5c90c22ece83"
      },
      "source": [
        "# Gets the MSE for a model with zero features (just predicting the mean)\n",
        "def get_base_mse(y):\n",
        "    predictions = [np.mean(y)] * len(y)\n",
        "    return mean_squared_error(predictions, y)\n",
        "\n",
        "# Gets the MSE of our model, for a given dataset, estimated with 10-fold cross-validation.\n",
        "def k_fold_mse(X, y):\n",
        "    scores_mse = cross_validate(model, X, y, scoring = 'neg_mean_squared_error', cv = kfold)\n",
        "    return np.mean(scores['test_score']) * -1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6345ac0-72c2-4e70-a1f2-721ce7237f6a",
      "metadata": {
        "id": "d6345ac0-72c2-4e70-a1f2-721ce7237f6a"
      },
      "source": [
        "$R^2$:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a40e51-f4b2-4cf0-96a1-ac219f6e7813",
      "metadata": {
        "id": "49a40e51-f4b2-4cf0-96a1-ac219f6e7813"
      },
      "source": [
        "#### Linear Regression:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d47e7a8-2319-4656-b77d-6f18cfff9fca",
      "metadata": {
        "id": "0d47e7a8-2319-4656-b77d-6f18cfff9fca",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "##### Statsmodel, outliers and high leverege points:"
      ]
    },
    {
      "cell_type": "code",
      "id": "319bbb53-ecfa-4d68-8ab9-26dc74ca9201",
      "metadata": {
        "id": "319bbb53-ecfa-4d68-8ab9-26dc74ca9201",
        "outputId": "22d7fcfe-38b2-4668-94a0-b9b1cc6e786e"
      },
      "source": [
        "#Statsmodel fitting, it is used to show the p-values\n",
        "X_stat = sm.add_constant(concrete_df.iloc[:,1:])\n",
        "y_stat = concrete_df.concrete_compressive_strength\n",
        "\n",
        "statmodel = sm.OLS(y_stat,X_stat)\n",
        "estimate = statmodel.fit()\n",
        "\n",
        "print(estimate.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a58eae6-e87b-40bd-96b3-adc78c7b6d6c",
      "metadata": {
        "id": "6a58eae6-e87b-40bd-96b3-adc78c7b6d6c"
      },
      "source": [
        "According to the result of the fitted model, there is a relationship between the response of concrete compressive strength and **cement, blast furnace slag, fly ash, water, superplasticizer and age**, because they have low p-values, which is smaller than 0.05."
      ]
    },
    {
      "cell_type": "code",
      "id": "aa47e639-e764-4d96-848b-e6bea5d38c17",
      "metadata": {
        "id": "aa47e639-e764-4d96-848b-e6bea5d38c17"
      },
      "source": [
        "# Obtain the residuals, studentized residuals and the leverages\n",
        "fitted_values = estimate.fittedvalues\n",
        "residuals = estimate.resid.values\n",
        "studentized_residuals = OLSInfluence(estimate).resid_studentized_internal\n",
        "leverages = OLSInfluence(estimate).influence"
      ]
    },
    {
      "cell_type": "code",
      "id": "8ee79d69-ad90-4a6b-a2d4-74c0ec264495",
      "metadata": {
        "id": "8ee79d69-ad90-4a6b-a2d4-74c0ec264495",
        "outputId": "50ced06c-a239-499e-c736-110355f219fa"
      },
      "source": [
        "# Calculate thresholds\n",
        "n = len(fitted_values)\n",
        "p = X.shape[1] - 1  # exclude constant\n",
        "leverage_thresh = (p + 1) / n\n",
        "\n",
        "# Convert to arrays\n",
        "studentized_residuals = np.asarray(studentized_residuals)\n",
        "leverages = np.asarray(leverages)\n",
        "\n",
        "# Identify outlier indices\n",
        "outlier_indices = np.where(np.abs(studentized_residuals) > 3)[0]\n",
        "high_leverage_indices = np.where(leverages > leverage_thresh)[0]\n",
        "outliers = []\n",
        "for idx in outlier_indices:\n",
        "    outliers.append(idx)\n",
        "print(\"Outliers are:\",outliers)\n",
        "\n",
        "# Find common indices (both outlier and high leverage)\n",
        "joint_outliers = np.intersect1d(outlier_indices, high_leverage_indices)\n",
        "high_leverage_and_outliers = []\n",
        "\n",
        "for idx in joint_outliers:\n",
        "    high_leverage_and_outliers.append(idx)\n",
        "print(\"Comments on joint outliers (in both ax2 and ax3):\",high_leverage_and_outliers)\n",
        "\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
        "\n",
        "# 1. Residuals plot\n",
        "ax1.scatter(fitted_values, residuals, facecolors='none', edgecolors='b')\n",
        "ax1.set_xlabel('Fitted values')\n",
        "ax1.set_ylabel('Residuals')\n",
        "\n",
        "# 2. Studentized Residuals plot\n",
        "ax2.scatter(fitted_values, studentized_residuals, facecolors='none', edgecolors='b')\n",
        "ax2.axhline(y=3, color='r', linestyle='--', linewidth=1)\n",
        "ax2.axhline(y=-3, color='r', linestyle='--', linewidth=1)\n",
        "# Mark joint outliers\n",
        "for idx in joint_outliers:\n",
        "    ax2.scatter(fitted_values[idx], studentized_residuals[idx], color='red')\n",
        "    ax2.annotate(idx, (fitted_values[idx], studentized_residuals[idx]), color='red', fontsize=8)\n",
        "ax2.set_xlabel('Fitted values')\n",
        "ax2.set_ylabel('Studentized residuals')\n",
        "\n",
        "# 3. Leverage vs Studentized Residuals\n",
        "ax3.scatter(leverages, studentized_residuals, facecolors='none', edgecolors='b')\n",
        "ax3.axhline(y=3, color='r', linestyle='--', linewidth=1)\n",
        "ax3.axhline(y=-3, color='r', linestyle='--', linewidth=1)\n",
        "ax3.axvline(x=leverage_thresh, color='g', linestyle='--', linewidth=1)\n",
        "# Mark joint outliers\n",
        "for idx in joint_outliers:\n",
        "    ax3.scatter(leverages[idx], studentized_residuals[idx], color='red')\n",
        "    ax3.annotate(idx, (leverages[idx], studentized_residuals[idx]), color='red', fontsize=8)\n",
        "ax3.set_xlabel('Leverage')\n",
        "ax3.set_ylabel('Studentized residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574fadd4-fa96-4cd0-8392-df3564aceedf",
      "metadata": {
        "id": "574fadd4-fa96-4cd0-8392-df3564aceedf"
      },
      "source": [
        "The residuals display a clear pattern, which suggests **non-linearity** in the data. The studentized residuals indicate the presence of two outliers. The leverage plot also reveals several high-leverage pointsâ€”defined as points with leverage greater than $(p+1)/n=9/1030\\approx 0.009$. Notably, both outliers are also high-leverage points. However, since the dataset does not clearly define criteria for excluding data points, all observations, including the outliers, are retained for the subsequent analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eecc8fba-5663-4950-bc04-4c59101b9cae",
      "metadata": {
        "id": "eecc8fba-5663-4950-bc04-4c59101b9cae"
      },
      "source": [
        "##### Scikit-Model:"
      ]
    },
    {
      "cell_type": "code",
      "id": "3f3bd025-2dfd-4090-a916-9fb04bc94246",
      "metadata": {
        "id": "3f3bd025-2dfd-4090-a916-9fb04bc94246",
        "outputId": "e1cdab83-7a99-444d-a93d-ec636065930a"
      },
      "source": [
        "# Scikit-Model\n",
        "model = LinearRegression()\n",
        "mse_per_fold_lin = []\n",
        "\n",
        "for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    mse_per_fold_lin.append(mse)\n",
        "\n",
        "    # Print fold summary: remove the\"#\"\n",
        "    # print(f\"\\n--- Fold {i+1} ---\")\n",
        "    # print(f\"MSE: {mse:.4f}\")\n",
        "    # print(f\"Intercept: {model.intercept_:.4f}\")\n",
        "    # print(f\"Coefficients: {model.coef_}\")\n",
        "print(\"MSE for each fold:\",mse_per_fold_lin)\n",
        "print(\"\\nAverage MSE across folds:\", np.mean(mse_per_fold_lin))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7471f06-b00b-4a8c-a179-5cbfab50a025",
      "metadata": {
        "id": "a7471f06-b00b-4a8c-a179-5cbfab50a025"
      },
      "source": [
        "#### Polynomial Regression:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50af8a73-f235-4217-8827-ead5ff869205",
      "metadata": {
        "id": "50af8a73-f235-4217-8827-ead5ff869205"
      },
      "source": [
        "Since there is non-linearity in the data, we use the polynomial regression to train the dataset."
      ]
    },
    {
      "cell_type": "code",
      "id": "a49577e8-d7ae-45f0-b7fc-df7b869e8db0",
      "metadata": {
        "id": "a49577e8-d7ae-45f0-b7fc-df7b869e8db0",
        "outputId": "6a729f3d-2522-4bbc-d321-9ebd2885849a"
      },
      "source": [
        "# Create MSE scorer for polynomial regression\n",
        "mse_scorer = make_scorer(mean_squared_error)\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "for feature in feature_columns:\n",
        "\n",
        "    #Store MSE\n",
        "    mse_poly = []\n",
        "\n",
        "    for degree in range(1, 6):  # Degrees 1 to 5\n",
        "            # Create polynomial features\n",
        "            poly = PolynomialFeatures(degree=degree)\n",
        "            X_poly = poly.fit_transform(X)\n",
        "\n",
        "            # Create linear regression model\n",
        "            model = LinearRegression()\n",
        "\n",
        "            # Perform 10-fold CV and get negative MSE (sklearn returns negative MSE by default)\n",
        "            mse_scores = cross_val_score(model, X_poly, y, scoring=mse_scorer, cv=10)\n",
        "\n",
        "            # Store average MSE\n",
        "            mse_poly.append(np.mean(mse_scores))\n",
        "\n",
        "        # Store MSEs for this feature\n",
        "    results[feature] = mse_poly\n",
        "    # Plot results\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for feature, mse_list in results.items():\n",
        "    plt.plot(range(1, 6), mse_list, marker='o', label=feature)\n",
        "\n",
        "    # Sort MSEs with their degree indices\n",
        "    sorted_mse = sorted((mse, i+1) for i, mse in enumerate(mse_list))  # (MSE, degree)\n",
        "\n",
        "    min_mse, best_degree = sorted_mse[0]\n",
        "    second_min_mse, second_best_degree = sorted_mse[1]\n",
        "\n",
        "    print(f\"{feature}:\")\n",
        "    print(f\"  Lowest MSE = {min_mse:.2f} at degree {best_degree}\")\n",
        "    print(f\"  Second Lowest MSE = {second_min_mse:.2f} at degree {second_best_degree}\")\n",
        "\n",
        "plt.xlabel('Polynomial Degree')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Polynomial Regression MSE (Each Feature Individually)')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1b3e436-f5a9-4458-9288-28d991ac14b5",
      "metadata": {
        "id": "b1b3e436-f5a9-4458-9288-28d991ac14b5"
      },
      "source": [
        "$\\text{concrete\\_compressive\\_strength} = \\beta_0\n",
        "+ \\beta_1 \\cdot \\text{cement}\n",
        "+ \\beta_2 \\cdot \\text{blast\\_furnace\\_slag}^5\n",
        "+ \\beta_3 \\cdot \\text{fly\\_ash}^4\n",
        "+ \\beta_4 \\cdot \\text{water}^4\n",
        "+ \\beta_5 \\cdot \\text{superplasticizer}\n",
        "+ \\beta_6 \\cdot \\text{coarse\\_aggregate}^2\n",
        "+ \\beta_7 \\cdot \\text{fine\\_aggregate}\n",
        "+ \\beta_8 \\cdot \\text{age}^4\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b6d1d4-c0af-4cfa-b738-25c7e8224c5b",
      "metadata": {
        "id": "82b6d1d4-c0af-4cfa-b738-25c7e8224c5b"
      },
      "source": [
        "#### Polynomial Degree Selection Summary and Justification:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99cb3d47-7d0c-4684-b546-c74db7a44e3a",
      "metadata": {
        "id": "99cb3d47-7d0c-4684-b546-c74db7a44e3a"
      },
      "source": [
        "In order to model the relationship between the features and the concrete compressive strength, polynomial regression up to degree 5 is applied for each feature. The mean squared error (MSE) was computed using 10-fold cross-validation to assess the predictive performance at each polynomial degree.\n",
        "\n",
        "While some features achieved their lowest MSE at higher degrees, the improvements over lower degrees were often marginal. Since high-degree polynomial models tend to overfitâ€”capturing noise instead of the underlying patter. Both the lowest and second-lowest MSEs are considered for each feature to guide model complexity choices."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b3125a9-2293-4963-bc1b-6ed987e16fc0",
      "metadata": {
        "id": "2b3125a9-2293-4963-bc1b-6ed987e16fc0"
      },
      "source": [
        "Below is a summary of the best and second-best MSEs and their associated degrees:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63f70e5d-2e16-4955-bf0d-665788fd8e59",
      "metadata": {
        "id": "63f70e5d-2e16-4955-bf0d-665788fd8e59"
      },
      "source": [
        "| Feature            | Lowest MSE | Degree | Second Lowest MSE | Degree |\n",
        "| ------------------ | ---------- | ------ | ----------------- | ------ |\n",
        "| Cement             | 232.98     | 1      | 235.47            | 2      |\n",
        "| Blast Furnace Slag | 303.89     | 5      | 304.91            | 2      |\n",
        "| Fly Ash            | 317.01     | 4      | 317.38            | 1      |\n",
        "| Water              | 248.95     | 4      | 259.49            | 3      |\n",
        "| Superplasticizer   | 272.21     | 1      | 277.66            | 2      |\n",
        "| Coarse Aggregate   | 296.42     | 2      | 296.86            | 1      |\n",
        "| Fine Aggregate     | 293.30     | 1      | 295.24            | 2      |\n",
        "| Age                | 206.15     | 4      | 211.45            | 5      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efea66f1-d919-4d2e-8fc7-3ce7a40cf6bb",
      "metadata": {
        "id": "efea66f1-d919-4d2e-8fc7-3ce7a40cf6bb"
      },
      "source": [
        "In features such as blast furnace slag and fly ash, the difference in MSE between the best and second-best degrees is negligible (â‰ˆ1 unit). In such cases, lower-degree polynomials were selected to avoid overfitting while maintaining nearly optimal performance. For example, blast furnace slag was assigned degree 2 instead of 5 due to only a 1.02 unit difference in MSE.\n",
        "Consequently, degree 4 was the highest degree ultimately selected across all features. Therefore, the maximum polynomial degree for the multivariate polynomial regression model was set to 4. This approach ensures a balance between model flexibility and generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be884505-609f-4b0c-9ed7-1b9457c31a3e",
      "metadata": {
        "id": "be884505-609f-4b0c-9ed7-1b9457c31a3e"
      },
      "source": [
        "#### Ridge regression:"
      ]
    },
    {
      "cell_type": "code",
      "id": "eb36ba06-fc58-49e3-83a5-fd59349268a2",
      "metadata": {
        "id": "eb36ba06-fc58-49e3-83a5-fd59349268a2"
      },
      "source": [
        "label_column = 'concrete_compressive_strength'\n",
        "feature_columns = ['cement', 'blast_furnace_slag', 'fly_ash', 'water', 'superplasticizer', 'coarse_aggregate', 'fine_aggregate', 'age']\n",
        "X_raw = concrete_df[feature_columns].values\n",
        "y_raw = concrete_df[label_column].values\n",
        "p = len(feature_columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b20ef2d-5f6a-4f02-9277-ba43adfc3e2b",
      "metadata": {
        "id": "1b20ef2d-5f6a-4f02-9277-ba43adfc3e2b"
      },
      "source": [
        "Since degree 4 was the highest optimal degree observed across all features after this adjustment, we selected degree 4 as the maximum polynomial degree"
      ]
    },
    {
      "cell_type": "code",
      "id": "0a63e48f-372f-48fa-a905-48f6428ae80a",
      "metadata": {
        "id": "0a63e48f-372f-48fa-a905-48f6428ae80a"
      },
      "source": [
        "# define the model\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "model = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    PolynomialFeatures(degree=2),\n",
        "    GridSearchCV(\n",
        "        estimator = Ridge(),\n",
        "        cv = kfold,\n",
        "        scoring = 'neg_mean_squared_error',\n",
        "\n",
        "        # param_grid determines the parameters to test (alpha is lambda in the Ridge estimator)\n",
        "        # np.logspace(-3, 2, 50): array from 10^-3 to 10^2 in 50 steps (base default is 10, can also be something else)\n",
        "        param_grid = {'alpha': np.logspace(-3, 2, 50)},\n",
        "    )\n",
        ")\n",
        "model.fit(X_raw, y_raw)\n",
        "\n",
        "# obtain the results\n",
        "lambdas = [p['alpha'] for p in model[2].cv_results_['params']]\n",
        "mses = [neg_mse * -1 for neg_mse in model[2].cv_results_['mean_test_score']]\n",
        "best_model = model.named_steps['gridsearchcv'].best_estimator_\n",
        "best_mse = min(mses)\n",
        "best_lambda = lambdas[np.argmin(mses)]\n",
        "\n",
        "print(f\"Best alpha:{best_lambda}:with MSE: {best_mse:.2f}\")\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "id": "8e4c67fc-2c05-467d-b652-0a0e7955a5ec",
      "metadata": {
        "id": "8e4c67fc-2c05-467d-b652-0a0e7955a5ec"
      },
      "source": [
        "# plot the reults\n",
        "fig, ax = plt.subplots(figsize = (12, 8))\n",
        "ax.plot(lambdas, mses)\n",
        "ax.set_xscale('log')\n",
        "ax.set_title(r\"MSE as a function of $\\lambda$\")\n",
        "ax.set_xlabel(r\"Hyper-parameter $\\lambda$\")\n",
        "ax.set_ylabel(\"Estimated MSE\");\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ba6dc9-4a23-4852-b1de-95a32eea3540",
      "metadata": {
        "id": "18ba6dc9-4a23-4852-b1de-95a32eea3540"
      },
      "source": [
        "The ridge regression was evaluated across a range of Î» values from $10^{-3}$ to $10^2$. The validation MSE decreased with small increases in Î» due to reduced overfitting, reaching a minimum at Î» = 4.71. Beyond this point, further increases in Î» caused the model to underfit the data, resulting in higher MSEs.\n",
        "Thus, the optimal Î» value was selected as 4.71, where the model achieved the lowest MSE of 34.56."
      ]
    },
    {
      "cell_type": "code",
      "id": "6bbf8a91-91fb-4a7b-985f-bc4446c5c85c",
      "metadata": {
        "id": "6bbf8a91-91fb-4a7b-985f-bc4446c5c85c"
      },
      "source": [
        "lambdas = np.logspace(-3, 6, 50)\n",
        "coefficients = list()\n",
        "\n",
        "# for each lambda define and fit the model and save the obtained parameters in the coefficients list\n",
        "for lam in lambdas:\n",
        "    model = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        PolynomialFeatures(degree = 2),\n",
        "        Ridge(alpha = lam)\n",
        "    )\n",
        "    model.fit(X_raw, y_raw)\n",
        "    coefficients.append(model[2].coef_)\n",
        "\n",
        "\n",
        "# plot the results\n",
        "coefficients = np.array(coefficients).T\n",
        "fig, ax = plt.subplots(figsize = (12, 10))\n",
        "\n",
        "for coef_vals in coefficients:\n",
        "    ax.plot(lambdas, coef_vals)\n",
        "\n",
        "ax.set_xlabel(r\"Hyper-parameter $\\lambda$\")\n",
        "ax.set_ylabel(r\"Value of the model coefficients $\\beta_i$\")\n",
        "ax.set_xscale('log');"
      ]
    },
    {
      "cell_type": "code",
      "id": "3b0bc56e-d21c-4032-b1d9-2bbd913d8266",
      "metadata": {
        "id": "3b0bc56e-d21c-4032-b1d9-2bbd913d8266"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_raw, y_raw, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "id": "e35eec66-c12d-4688-81ac-ba47b0e87f98",
      "metadata": {
        "id": "e35eec66-c12d-4688-81ac-ba47b0e87f98"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "id": "6463d774-c8fc-4a4a-b010-8d5ca104125d",
      "metadata": {
        "id": "6463d774-c8fc-4a4a-b010-8d5ca104125d"
      },
      "source": [
        "model = Ridge(alpha=best_lambda)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Test MSE: {mse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f146ad13-cabf-4845-8997-b959669119b6",
      "metadata": {
        "id": "f146ad13-cabf-4845-8997-b959669119b6"
      },
      "source": [
        "#show the model\n",
        "feature_names = ['cement', 'blast_furnace_slag', 'fly_ash', 'water',\n",
        "                 'superplasticizer', 'coarse_aggregate',\n",
        "                 'fine_aggregate', 'age']\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "#show the equation\n",
        "equation = f\"concrete compressive strength = {intercept:.3f}\"\n",
        "for coef, name in zip(coefficients, feature_names):\n",
        "    equation += f\" + ({coef:.3f} * {name})\"\n",
        "print(equation)"
      ]
    },
    {
      "cell_type": "code",
      "id": "7e749760-f7a2-448f-8485-9bf9052e62ed",
      "metadata": {
        "id": "7e749760-f7a2-448f-8485-9bf9052e62ed"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

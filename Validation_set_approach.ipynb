{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validation set approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import all the packages and functions needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the data from the file Auto.csv and remove all columns that are not complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auto = pd.read_csv('./Data/Auto.csv',na_values='?')\n",
        "auto = auto.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to predict the mpg from the horsepower in the auto dataframe. In the simple linear regression task we already saw, that the linear fit may not be the best choice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "a) Randomly split the data into a training and test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "training = np.random.choice([False,True], size=392)\n",
        "\n",
        "y_train = auto.mpg[training]\n",
        "X_train = sm.add_constant(auto.horsepower[training])\n",
        "\n",
        "y_test = auto.mpg[~training]\n",
        "X_test = sm.add_constant(auto.horsepower[~training])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b) Fit a linear regression model on the training set and compute the MSE with the predictions on the validation set (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear_model = sm.OLS(y_train, X_train)\n",
        "linear_results = linear_model.fit()\n",
        "\n",
        "y_predictions = linear_results.predict(X_test)\n",
        "mse = np.mean((y_predictions - y_test) ** 2)\n",
        "print(f'Mean Squared Error: {mse:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "c) Fit a quadratic regression model on the training set and compute the MSE with the predictions on the validation set (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = sm.add_constant(np.column_stack((auto.horsepower[training], auto.horsepower[training]**2)))\n",
        "X_test = sm.add_constant(np.column_stack((auto.horsepower[~training], auto.horsepower[~training]**2)))\n",
        "\n",
        "quad_model = sm.OLS(y_train, X_train)\n",
        "quad_results = quad_model.fit()\n",
        "\n",
        "y_predictions_quad = quad_results.predict(X_test)\n",
        "mse_quad = np.mean((y_predictions_quad - y_test) ** 2)  \n",
        "print(f'Mean Squared Error (Quadratic): {mse_quad:.4f}')   \n",
        "# Compare the two models\n",
        "if mse_quad < mse:\n",
        "    print(\"The quadratic model has a lower MSE than the linear model.\") \n",
        "else:\n",
        "    print(\"The linear model has a lower MSE than the quadratic model.\")\n",
        "# Display the summary of the quadratic model\n",
        "print(quad_results.summary())\n",
        "# Display the summary of the linear model\n",
        "print(linear_results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "d) Fit a cubic regression model on the training set and compute the MSE with the predictions on the validation set (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = sm.add_constant(np.column_stack((auto.horsepower[training], auto.horsepower[training] ** 2, auto.horsepower[training] ** 3)))\n",
        "X_test = sm.add_constant(np.column_stack((auto.horsepower[~training], auto.horsepower[~training] ** 2, auto.horsepower[~training] ** 3)))\n",
        "\n",
        "model = sm.OLS(y_train, X_train)\n",
        "cubic_results = model.fit()\n",
        "\n",
        "y_predictions_cubic = cubic_results.predict(X_test)\n",
        "mse_cubic = np.mean((y_predictions_cubic - y_test) ** 2)\n",
        "print(f'Mean Squared Error (Cubic): {mse_cubic:.4f}\\n')\n",
        "# Compare the cubic model with the previous models\n",
        "if mse_cubic < mse_quad and mse_cubic < mse:\n",
        "    print(\"The cubic model has the lowest MSE among all models.\")\n",
        "else:\n",
        "    print(\"The cubic model does not have the lowest MSE compared to the previous models.\")\n",
        "# Display the summary of the cubic model\n",
        "print(cubic_results.summary())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
